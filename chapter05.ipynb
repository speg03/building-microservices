{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5章 モノリスの分割"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 すべては接合部次第\n",
    "\n",
    "* サービスは凝集性を高め、疎結合にしたい\n",
    "* モノリスは大抵どちらにも反している\n",
    "* モノリスはシステム全体をデプロイしなおさなければいけない\n",
    "\n",
    "* コードベースを整理するために接合部を探すのではなく、サービス境界となる接合部を特定したい"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 MusicCorpの分解\n",
    "\n",
    "* MusicCorp: オンラインシステム、大規模なバックエンドモノリシックサービス\n",
    "\n",
    "\n",
    "* まずは、組織のコンテキスト境界を特定し、モノリスの対応するコンテキスト境界を把握\n",
    "    * 既存コードをコンテキストを表すパッケージに分類していく\n",
    "    * IDEでリファクタリングすることが難しい言語を利用している場合は、破壊を捕捉するテストも必要\n",
    "\n",
    "\n",
    "* 分類できなかったコードから見逃したコンテキストを特定できる\n",
    "\n",
    "\n",
    "* パッケージ間の依存関係と、実際の組織間の依存関係（対話関係）が合っているかどうか\n",
    "    * 実際にはやり取りしていない組織なのに、パッケージ間で依存があればおかしい"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 モノリスを分割する理由\n",
    "\n",
    "* モノリスの分割は少しずつ進めていくことでマイクロサービスについて学ぶ手助けとなるし、間違いの影響も制限される\n",
    "\n",
    "\n",
    "* コードベースのどの部分を分離したら最も恩恵が得られるかを考えるのが最善\n",
    "    * 変化の速度\n",
    "        * 在庫の管理方法には短時間で大量の変更が発生してしまうことがわかるでしょう（？）\n",
    "        * よく変更される箇所は独立させたほうがいいということ\n",
    "    * チーム構成\n",
    "        * 物理的に離れたところにいるチーム単位で分割するといい → 詳しくは10章\n",
    "    * セキュリティ\n",
    "        * 現在はセキュリティ監査のため経理関連のコードですべて対処している\n",
    "        * このサービスのコードを分割したら、監視、転送データの保護、格納データの保護に関してこの別個のサービスに保護を追加できます（？） → 詳しくは9章\n",
    "    * 技術\n",
    "        * 使用する技術要素（プログラミング言語など）の単位でサービス分割\n",
    "        * そうすると、テスト対象の代替実装の構築を検討しやすくなるでしょう（？）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 入り組んだ依存関係\n",
    "\n",
    "* できれば依存関係の少ない接合部を取り出したい\n",
    "* 入り組んだ依存関係の原因となることが多いのはデータベース"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 データベース\n",
    "\n",
    "* 複数のサービスの統合手法としてデータベースを利用することは勧められない（前の章で説明している）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 問題の対処\n",
    "\n",
    "* データベースアクセスを行う部分を同じようにコンテキスト境界で分割したい\n",
    "    * Hibernateなどを利用しているリポジトリレイヤを一枚岩ではなく分割したい\n",
    "\n",
    "\n",
    "* コード上は別のコンテキストのテーブルを使っていることがわかっていても、実際にそのテーブル間でデータベース上の依存関係があるかどうかはわからない\n",
    "    * SchemaSpy: テーブル間の関係をグラフィカルな表現で確認できる\n",
    "\n",
    "\n",
    "* テーブル間の結びつきを断ち切るのは簡単ではないが対処は可能\n",
    "* 次の節から方法を見ていく"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.7 例：外部キー関係の削除\n",
    "\n",
    "* 例: 経理の売上情報で品物の名前を品目テーブルから引きたい\n",
    "* 修正: 経理パッケージはカタログパッケージのAPI経由で品物の名前を取得する\n",
    "\n",
    "\n",
    "* 異なるデータベースのアクセスとなるとパフォーマンスの懸念が出てくる\n",
    "    * 実際に問題となるかどうかをテストすること\n",
    "    * 必要なパフォーマンスは? 現状のパフォーマンスは?\n",
    "    * 複数のデータベースアクセスを行っていても、必要なパフォーマンスが確保できているのであれば問題ない\n",
    "\n",
    "\n",
    "* 外部キー関係が分断される\n",
    "    * 一貫性検査を実装するか、関連データを整理する措置\n",
    "    * 多くの場合、技術者が判断することではない\n",
    "    * 不完全なデータが存在したときにどうするかを、システムの振る舞いを決める人に答えてもらう\n",
    "    * その上でどんな機能が必要かが明確になる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.8 例：共有静的データ\n",
    "\n",
    "* 例: 国コード（サポートする国が頻繁に更新される予定）\n",
    "\n",
    "\n",
    "* 選択肢1: パッケージ/サービスごとにテーブルを重複して持つ\n",
    "    * 一貫性の課題（一部の更新忘れ）が起こる可能性\n",
    "* 選択肢2: 共有静的データをコードとして扱う\n",
    "    * プロパティファイルか列挙型か\n",
    "    * 稼働中のデータベースを変更するよりもはるかに簡単（？） → デプロイし直す手間のほうが大きいような？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.9 例：共有データ\n",
    "\n",
    "* 例: 経理コードと倉庫コードがそれぞれ支払いと在庫の管理を同じ顧客レコードテーブルに書き込んでいる\n",
    "    * 顧客パッケージ/サービスとして切り出せる\n",
    "    * 外部キー関係の問題が発生する？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.10 例：共有テーブル\n",
    "\n",
    "* 例: カタログコードが品目の名前と価格、倉庫コードが在庫を管理しており、どちらも品目テーブルに書き込んでいる\n",
    "    * カタログ品目と在庫水準（？）に分割する\n",
    "    * やはり外部キー関係の問題が発生する？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.11 データベースリファクタリング\n",
    "\n",
    "* スキーマの分割 → サービスの分割の順番に行うのがオススメ\n",
    "    * 2つのスキーマ（データベース）に分割されるとトランザクション完全性（整合性）が失われてしまう\n",
    "    * いつでも元の構成に戻せる状態で、重大な影響がないかを確認したのちにサービス（アプリケーションコード）を分割する\n",
    "    * 詳しくは次の節で説明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.12 トランザクション境界\n",
    "\n",
    "* スキーマを分割するとトランザクションも分割されてしまう\n",
    "\n",
    "\n",
    "* 5.12.1 後でリトライ\n",
    "    * 失敗したトランザクションを後からリトライすることでいずれは求めていた状態になるようにする\n",
    "    * 結果整合性: トランザクション境界を利用してトランザクション完了時にシステムが一貫性のある状態になることを保証する代わりに、システムが将来のある時点で一貫性のある状態になることを受け入れる\n",
    "    * 詳しくは11章スケーリングのパターンで\n",
    "\n",
    "\n",
    "* 5.12.2 操作全体の中止\n",
    "    * 先行して成功してしまったトランザクションを打ち消すような補正（補償）トランザクションを発行\n",
    "    * 補正トランザクションも失敗するとどうするか → リトライあるいは、バックエンドプロセスで非一貫性を取り除く仕組み\n",
    "    * 一貫性を保ちたい操作が多くなればなるほど対応は困難\n",
    "\n",
    "\n",
    "* 5.12.3 分散トランザクション\n",
    "    * トランザクションマネージャ: 全体のトランザクションを管理するプロセス\n",
    "    * 2フェーズ（2相）コミット\n",
    "        * 投票フェーズ: 分散トランザクション参加者がローカルトランザクションを進められるかどうか確認 → 1つでも「いいえ」があれば、全参加者にロールバックを送信\n",
    "        * 投票の応答に失敗したときに全体が停止してしまう\n",
    "        * 「はい」と答えたらコミットできるとみなすが、実際は失敗してしまった場合\n",
    "        * 絶対確実なアルゴリズムではない\n",
    "\n",
    "\n",
    "* 5.12.4 何をすべきか\n",
    "    * 分散トランザクション\n",
    "        * 正しく実行するのが困難\n",
    "        * スケーリングを妨げる\n",
    "        * データの非一貫性を修正するために補正動作が必要になる場合がある\n",
    "    * 結果整合性にできないか\n",
    "        * この方が構築やスケーリングが簡単 → 詳しくは11章\n",
    "    * 本当に一貫性を維持したい場合\n",
    "        * トランザクション自体を表す具体的な概念を作成（例: 処理中の注文）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.13 レポート\n",
    "\n",
    "* データの格納方法や格納場所を分割するとレポートの作成で問題になる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.14 レポートデータベース\n",
    "\n",
    "* モノリシックサービスの場合\n",
    "    * プライマリデータベースから定期的に同期したレポートレプリカを、レポートシステムが利用する\n",
    "\n",
    "\n",
    "* データベースのスキーマがモノリシックサービスとレポートシステムで共有APIとなる\n",
    "    * スキーマの変更を慎重にしなければいけない\n",
    "* サービスとレポートシステムの両方に適した最適化方法が限られる\n",
    "    * それぞれに最適なデータベースがある\n",
    "    * 両方ともに最適なものはまずない"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.15 サービス呼び出しを介したデータ取得\n",
    "\n",
    "* 少ないデータだけを必要とするレポートでは、サービス呼び出しを介してデータを取得すればよい\n",
    "* 大量データを必要とする場合には機能しなくなる\n",
    "* 公開されているAPIはおそらくレポート向けに設計されていない\n",
    "    * 顧客をIDで引くことはできても、すべての顧客を取得するAPIはないかもしれない\n",
    "\n",
    "\n",
    "* バッチ用APIを作成する\n",
    "* リクエストを受けるとHTTP 202(Accepted)をすぐに返して、共有場所にファイルとして出力する\n",
    "* 呼び出し側はHTTP 201(Created)が返るまでポーリングしてから、共有場所にファイルを取りに行く"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.16 データポンプ\n",
    "\n",
    "* HTTP呼び出しの欠点\n",
    "    * 多数の呼び出しを行ったときのオーバーヘッド\n",
    "    * レポート専用のAPIを作成しなければいけない\n",
    "\n",
    "\n",
    "* データベースからレポート用のデータを吸い出すスタンドアロンプログラム（データポンプ）\n",
    "    * レポート専用のデータベースに書き出す\n",
    "    * 同じデータベースに多くのプログラムがアクセスするべきではないが、これは特筆すべき例外\n",
    "\n",
    "\n",
    "* データポンプはサービスを管理するのと同じチームが構築・管理すべき\n",
    "    * サービス向けの内部データベースとレポートスキーマ両方の知識が必要\n",
    "\n",
    "\n",
    "* レポートスキーマ自体との結合は残る\n",
    "    * 変更が難しい公開APIとして扱わなければいけない\n",
    "    * このコストを軽減するテクニック\n",
    "        * レポートデータベースでは各サービスごとのスキーマを用意\n",
    "        * レポートツールから使用するスキーマをマテリアライズドビューで実現\n",
    "        * JBoss Data Virtualizationもこの領域\n",
    "\n",
    "\n",
    "* 5.16.1 代替手段\n",
    "    * S3を使った巨大データマート: ソリューションのスケーリングが必要になるまではとてもうまく機能 → なぜスケーリングできない?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.17 イベントデータポンプ\n",
    "\n",
    "* データが変更されたらイベントが発行され、それに対するイベントサブスクライバがレポートデータベースにデータを書き込む\n",
    "    * イベントサブスクライバ = レポートマッパー ?\n",
    "\n",
    "\n",
    "* どのイベントが既に処理済みか格納しておくと差分だけ処理できる\n",
    "    * レポートデータベースに処理済みイベントを格納?\n",
    "\n",
    "\n",
    "* イベントデータポンプはサービス内部とあまり結合しないのでサービス担当と別のグループで管理しやすい\n",
    "\n",
    "\n",
    "* イベントデータベースに必要なデータがすべてイベントに含まれている必要があるという欠点がある\n",
    "    * 大量のデータが必要な場合はスケーリングがうまくできない場合がある"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.18 バックアップデータポンプ\n",
    "\n",
    "* Netflixはバッキングストア（バックアップ先?）としてCassandraを使用\n",
    "    * SSTable（Sorted String Table: ソート済み文字列テーブル, Cassandraのファイル形式）をAmazon S3に格納\n",
    "    * Hadoopを利用してレポートを作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.19 リアルタイムを目指す\n",
    "\n",
    "* すべてのレポートを1箇所から行う考え方は本当に妥当なのか\n",
    "* 詳しくは8章"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.20 変更のコスト\n",
    "\n",
    "* 小さな変更を漸進的に行うこと\n",
    "* 間違いをなくすことはできないので受け入れること\n",
    "\n",
    "\n",
    "* 影響の大きいところは分割にコストがかかるし、元に戻すのも大変\n",
    "* 影響が最も少ないところで間違いを犯すようにする\n",
    "\n",
    "\n",
    "* CRC（Class-Responsibility-Collaboration、クラス-責務-協調）カード"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.21 根本原因の理解\n",
    "\n",
    "* なぜサービスが大きくなってしまうのか → それ自体に問題はない\n",
    "* 重要なのは、分割のコストが高くなりすぎる前に分割する必要があるかを判断すること\n",
    "\n",
    "\n",
    "* 新しいサービスを立ち上げやすくすること\n",
    "    * セルフサービスで仮想マシンをプロビジョニング、PaaSの利用など\n",
    "    * 次章から説明していく"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.22 まとめ\n",
    "\n",
    "* 接合部を探してシステムを分割し、漸進的な方法で実行\n",
    "* 最初の段階でのサービス分割のコストを減らすようにすると、継続的にシステムを成長、進化させられる"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
